{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "mysterious-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/train_dataset.txt'\n",
    "test_path = '../data/test_dataset.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-korean",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "extensive-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open('../data/PDS2.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "jewish-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_index = int(len(corpus) * .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "considerable-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, 'w') as train_file:\n",
    "    train_file.write(corpus[:training_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "french-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_path, 'w') as train_file:\n",
    "    train_file.write(corpus[training_index:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "tested-poverty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Corpus Size: 472508\n",
      "Testing Corpus Size: 118128\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Corpus Size: {len(corpus[:training_index])}')\n",
    "print(f'Testing Corpus Size: {len(corpus[training_index:])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "voluntary-certification",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "\n",
    "train_dataset = TextDataset(\n",
    "      tokenizer=tokenizer,\n",
    "      file_path=train_path,\n",
    "      block_size=128)\n",
    "\n",
    "test_dataset = TextDataset(\n",
    "      tokenizer=tokenizer,\n",
    "      file_path=test_path,\n",
    "      block_size=128)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False,  # MLM is Masked Language Modelling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "related-advertiser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it probably performed terribly on 80% of the forms! This is because the\n",
      "computer was probably great at simple forms. The claims that would have taken a human\n",
      "minutes to compute took the computer seconds. But these minutes add up, and before you\n",
      "know it, each human is being saved over an hour a day!\n",
      "Forms that might be easy for a human to read are also likely easy for the computer. It's\n",
      "when the forms are very terse, or when the writer starts deviating from the usual grammar,\n",
      "that the computer starts to fail. This model is great because it lets the humans spend more\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(train_dataset[100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "approximate-rebecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time on those difficult claims and gives them more attention without getting distracted by\n",
      "the sheer volume of papers.\n",
      "Note that I used the word \"model.\" Remember that a model is a\n",
      "relationship between elements. In this case, the relationship is between\n",
      "written words and the approval status of a claim.\n",
      "\n",
      "[ 24 ]\n",
      "\n",
      "\f",
      "How to Sound Like a Data Scientist\n",
      "\n",
      "Chapter 1\n",
      "\n",
      "Case study â€“ marketing dollars\n",
      "A dataset shows the relationships between TV, radio, and newspaper sales. The goal is to\n",
      "analyze the relationships between the three different marketing mediums and how they\n",
      "affect the sale of\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(train_dataset[101]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "romance-grace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Every effort has been made in the preparation of this book to ensure the accuracy of the information presented.\n",
      "However, the information contained in this book is sold without warranty, either express or implied. Neither the\n",
      "authors, nor Packt Publishing or its dealers and distributors, will be held liable for any damages caused or alleged to\n",
      "have been caused directly or indirectly by this book.\n",
      "Packt Publishing has endeavored to provide trademark information about all of the companies and products\n",
      "mentioned in this book by the appropriate use of capitals. However, Packt Publishing cannot guarantee the accuracy\n",
      "of this information.\n",
      "Commissioning Editor: Amey\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(train_dataset[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "damaged-designation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Size: 920\n",
      "Testing Dataset Size: 253\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Dataset Size: {len(train_dataset)}')\n",
    "print(f'Testing Dataset Size: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-flight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-harrison",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cognitive-welding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "stunning-elephant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
      "Model config GPT2Config {\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 6,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilgpt2/resolve/main/pytorch_model.bin from cache at /Users/sinanozdemir/.cache/huggingface/transformers/43a212e83e76bcb07f45be584cf100676bdbbbe9c13f9e5c1c050049143a832f.a83d881ec4d624fd4b5826dd026e315246c48c67504ff91c0500570e291a54ba\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at distilgpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
      "Model config GPT2Config {\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 6,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilgpt2/resolve/main/vocab.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/55051ac97dcc32f0a736d21a32a4d42b0d9b90f117ca7c38e65038b04bd5c3f5.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "loading file https://huggingface.co/distilgpt2/resolve/main/merges.txt from cache at /Users/sinanozdemir/.cache/huggingface/transformers/9dfb299b74cdf7601ba7cd3a8073dbdac351caec0ed7ab5849b098b3c8ae3d57.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/distilgpt2/resolve/main/tokenizer.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/accb287b5a5396b2597382916b6cc939fdab1366e89475a92338d3971b3d02b7.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "loading file https://huggingface.co/distilgpt2/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilgpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilgpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
      "Model config GPT2Config {\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 6,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('distilgpt2')\n",
    "\n",
    "pretrained_generator = pipeline(\n",
    "    'text-generation', model=model, tokenizer='distilgpt2',\n",
    "    config={'max_length': 200,  'do_sample': True, 'top_p': 0.9, 'temperatire': 0.7, 'top_k': 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "operating-merchant",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "A dataset shows the relationships between the number of users between individual users and their current active activity.\n",
      "\n",
      "\n",
      "\n",
      "A representative survey found that 70 per cent of US women of the age of 18 had an active activity pattern between August 20 and 1 2014\n",
      "----------\n",
      "A dataset shows the relationships between two datasets to date.\n",
      "\n",
      "\n",
      "\n",
      "References\n",
      "(3) A Permanente, Y. (2016). The relationship between the model and the data. NBER Working Paper , Volume 2, Issue 2,\n",
      "----------\n",
      "A dataset shows the relationships between the largest sub-groups of children in the country and the most common type of school-aged primary education in the country. Data for the U.S. Census, 2009, and 2010 were presented in this report.\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print('----------')\n",
    "for generated_sequence in pretrained_generator('A dataset shows the relationships', num_return_sequences=3):\n",
    "    print(generated_sequence['generated_text'])\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-vision",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-portugal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-powder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "wrapped-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2_pds\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=2, # number of training epochs\n",
    "    per_device_train_batch_size=32, # batch size for training\n",
    "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
    "    eval_steps = 10, # Number of update steps between two evaluations.\n",
    "    warmup_steps=100,# number of warmup steps for learning rate scheduler,\n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "electronic-brazilian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 253\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 26:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.090301036834717,\n",
       " 'eval_runtime': 78.1926,\n",
       " 'eval_samples_per_second': 3.236,\n",
       " 'eval_steps_per_second': 0.051}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "experienced-characterization",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 920\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 23:59, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.910700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.835300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.690800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.657700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=58, training_loss=3.7913445439831963, metrics={'train_runtime': 1468.1333, 'train_samples_per_second': 1.253, 'train_steps_per_second': 0.04, 'total_flos': 60098252636160.0, 'train_loss': 3.7913445439831963, 'epoch': 2.0})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "invalid-teens",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 253\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.6889734268188477,\n",
       " 'eval_runtime': 63.1809,\n",
       " 'eval_samples_per_second': 4.004,\n",
       " 'eval_steps_per_second': 0.063,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "developmental-newman",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./gpt2_pds\n",
      "Configuration saved in ./gpt2_pds/config.json\n",
      "Model weights saved in ./gpt2_pds/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "another-earthquake",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./gpt2_pds/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"distilgpt2\",\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 6,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file ./gpt2_pds/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./gpt2_pds.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "loaded_model = GPT2LMHeadModel.from_pretrained('./gpt2_pds')\n",
    "\n",
    "finetuned_generator = pipeline(\n",
    "    'text-generation', model=loaded_model, tokenizer=tokenizer,\n",
    "    config={'max_length': 200,  'do_sample': True, 'top_p': 0.9, 'temperatire': 0.7, 'top_k': 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "royal-shopping",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "A dataset shows the relationships between time, or the relationships between time and time, used to make a general rule. This rule makes sense if we apply other methods of estimating time and have an assumption that the distance between data points is different than that used\n",
      "----------\n",
      "A dataset shows the relationships between the average age of two children and their parents by age 15, and the average distance between each child and their parents in their neighborhood\n",
      "by age 15 between their parents and their parents in their neighborhood\n",
      "by age 15,\n",
      "----------\n",
      "A dataset shows the relationships between various characteristics, including:\n",
      "\n",
      "\n",
      "(1) means that\n",
      "\n",
      "(2) means both\n",
      "and\n",
      "(3) means that\n",
      "(4) means that\n",
      "(5) means that\n",
      "(6)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print('----------')\n",
    "for generated_sequence in finetuned_generator('A dataset shows the relationships', num_return_sequences=3):\n",
    "    print(generated_sequence['generated_text'])\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-wesley",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
