{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "approximate-gothic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "#load GPT2Tokenizer from transformers.\n",
    "\n",
    "# do_lower_case=False because programming codes are case sensitive for Python and Java\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", do_lower_case=False)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "#add special tokens, namely, the control codes <python> and <java>\n",
    "special_words_to_add={\"additional_special_tokens\": [\"<python>\", \"<java>\"]}\n",
    "tokenizer.add_special_tokens(special_words_to_add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-halifax",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "irish-lewis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 348\n",
       "})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "pandas_df = pd.DataFrame({})\n",
    "\n",
    "pandas_df['text'] = text\n",
    "\n",
    "pandas_df['text'] = pandas_df['text'].map(lambda x: f'<python> {x}')\n",
    "\n",
    "pandas_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "liable-halifax",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>&lt;python&gt; t('TAXJAR_API_KEY')\\n\\nENV = os.envir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>&lt;python&gt; \\n    'notifications',\\n    'art',\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>&lt;python&gt; )\\nBASE_DIR = os.path.dirname(os.path...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>&lt;python&gt; Pagination',\\n    'PAGE_SIZE': 100,\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>&lt;python&gt; ://preprod.getshiba.com', 'https://pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>&lt;python&gt; URL)\\n\\nDEFAULT_AUTO_FIELD = 'django....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>&lt;python&gt; BASE_URL', API_BASE_URL)\\n\\nDEFAULT_A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>&lt;python&gt; IL_BACKEND = 'django_ses.SESBackend'\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>&lt;python&gt; r production\\n# See https://docs.djan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>&lt;python&gt;                'https://shiba-prod-fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "120  <python> t('TAXJAR_API_KEY')\\n\\nENV = os.envir...\n",
       "331  <python> \\n    'notifications',\\n    'art',\\n ...\n",
       "39   <python> )\\nBASE_DIR = os.path.dirname(os.path...\n",
       "295  <python> Pagination',\\n    'PAGE_SIZE': 100,\\n...\n",
       "198  <python> ://preprod.getshiba.com', 'https://pr...\n",
       "67   <python> URL)\\n\\nDEFAULT_AUTO_FIELD = 'django....\n",
       "65   <python> BASE_URL', API_BASE_URL)\\n\\nDEFAULT_A...\n",
       "266  <python> IL_BACKEND = 'django_ses.SESBackend'\\...\n",
       "78   <python> r production\\n# See https://docs.djan...\n",
       "205  <python>                'https://shiba-prod-fi..."
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = Dataset.from_pandas(pandas_df)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-commander",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fitting-talent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d475ae2f2dbb40fcb2ea73ee1fe4d683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['attention_mask', 'input_ids', 'labels'],\n",
      "    num_rows: 348\n",
      "})\n",
      "CPU times: user 1.42 s, sys: 67.9 ms, total: 1.49 s\n",
      "Wall time: 1.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "MAX_TOKENS = 128\n",
    "\n",
    "output = {}\n",
    "# texts to numeric vectors of MAX_TOKENS\n",
    "def tokenize_function(examples, tokenizer=tokenizer):\n",
    "    # Add start and end token to each comment\n",
    "    examples = [ex + tokenizer.eos_token for ex in examples[\"text\"]]\n",
    "    # tokenizer created input_ids and attention_mask as output\n",
    "    output = tokenizer(\n",
    "        examples,\n",
    "        add_special_tokens=True,  # Only adds pad not eos and bos\n",
    "        max_length=MAX_TOKENS,\n",
    "        truncation=True,\n",
    "        pad_to_max_length=True,\n",
    "    )\n",
    "    # shift labels for next token prediction\n",
    "    # set padding token labels to -100 which is ignored in loss computation\n",
    "#     output[\"labels\"] = [x[1:] for x in output[\"input_ids\"]]\n",
    "    output[\"labels\"] = [\n",
    "        [-100 if x == tokenizer.pad_token_id else x for x in y]\n",
    "        for y in output[\"labels\"]\n",
    "    ]\n",
    "    # truncate input ids and attention mask to account for label shift\n",
    "#     output[\"input_ids\"] = [x[:-1] for x in output[\"input_ids\"]]\n",
    "#     output[\"attention_mask\"] = [x[:-1] for x in output[\"attention_mask\"]]\n",
    "    return output\n",
    "\n",
    "\n",
    "data = data.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    load_from_cache_file=True,\n",
    ")\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "subject-perspective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['attention_mask', 'input_ids', 'labels'],\n",
      "        num_rows: 278\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['attention_mask', 'input_ids', 'labels'],\n",
      "        num_rows: 70\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# data.set_format(type=\"python\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "data = data.train_test_split(\n",
    "    test_size=0.20, shuffle=True, seed=1, load_from_cache_file=True\n",
    ")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "manual-barrel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.resize_token_embeddings(len(tokenizer))  # Update the model embeddings with the new vocabulary size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "indian-registrar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'input_ids', 'labels'],\n",
       "    num_rows: 278\n",
       "})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-officer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "alone-folder",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2_autocoder\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=4, # number of training epochs\n",
    "    per_device_train_batch_size=32, # batch size for training\n",
    "    per_device_eval_batch_size=32,  # batch size for evaluation\n",
    "    warmup_steps=10,  # number of warmup steps for learning rate scheduler,\n",
    "    logging_steps=10\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=data['train'],\n",
    "    eval_dataset=data['test'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "uniform-participant",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 70\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 58:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 80.59626007080078,\n",
       " 'eval_runtime': 43.5323,\n",
       " 'eval_samples_per_second': 1.608,\n",
       " 'eval_steps_per_second': 0.069}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "responsible-clarity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 278\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 54:14, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>63.858500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>44.713300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>18.030900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=36, training_loss=36.503550635443794, metrics={'train_runtime': 3443.87, 'train_samples_per_second': 0.323, 'train_steps_per_second': 0.01, 'total_flos': 72071691264000.0, 'train_loss': 36.503550635443794, 'epoch': 4.0})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "noted-newman",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 70\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 7.404366493225098,\n",
       " 'eval_runtime': 23.7056,\n",
       " 'eval_samples_per_second': 2.953,\n",
       " 'eval_steps_per_second': 0.127,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "endless-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "generator = pipeline(\n",
    "    'text-generation', model=model, tokenizer=tokenizer,\n",
    "    config={'max_length': 100}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "enormous-masters",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<python> See https://en.wikipedia\n",
      "The name \"Shining\" means toSee https://en.wikipedia / Shining /Shining/Shining /Shining /Shining /LingeringTheLingering /Ling\n",
      "<python> See https://www.reddit.http://youtu.http://www.http://www.http://www.http://www.TheFreeSawTheWhiteWeep. / http/http. / http://http. /\n",
      "<python> See https://www.youtube.Use https://www.youtube. // www.youtube. Get https://(not www.)Gethttps www. Get www. }\n",
      "Get: www.\n",
      "<python> See https://thecSee https://I_i.com.i.I.,I.I.,I.I.I.,I.I.,i.,I.I.II.II.III.II.II\n",
      "<python> See https://www.youtube.YouSee https://www.youtube. YouSeeTheMuseum httpswww.facebook. TheMUSEBits httpswww.facebook. \"GIFM\" httpshttps httpsP1TheMUSE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for generated_text in generator(\"<python> See https\", num_return_sequences=5):\n",
    "    print(generated_text['generated_text'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-footage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
